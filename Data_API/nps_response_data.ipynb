{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Define Imports"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "import requests\n",
    "import pandas as pd \n",
    "import random\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.preprocessing import LabelEncoder, OneHotEncoder\n",
    "from sklearn.feature_extraction.text import TfidfVectorizer\n",
    "import json\n",
    "import sys\n",
    "\n",
    "sys.path.insert(0,'../')\n",
    "from environment import env"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Define Variables"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "config = env.env()\n",
    "api_key = config['nps_api_key']\n",
    "api_base_url = 'https://developer.nps.gov/api/v1/'"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Define Functions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_parks(params):\n",
    "    \"\"\"\n",
    "    Use to find a list of all park names, codes, states, addresses and descriptions from the NPS parks endpoint.\n",
    "    Can also be used to find specific park information.\n",
    "\n",
    "    \"\"\"\n",
    "    parks = []\n",
    "    limit = 50  # Number of results per page, maximum allowed by NPS API\n",
    "    start = 0   # Initial starting point for pagination\n",
    "    \n",
    "    while True:\n",
    "        params['limit'] = limit\n",
    "        params['start'] =  start\n",
    "        \n",
    "        response = requests.get(f\"{api_base_url}parks\", params=params)\n",
    "        data = response.json()\n",
    "        \n",
    "        parks.extend([\n",
    "            {\n",
    "                'fullName': park['fullName'],\n",
    "                'parkCode': park['parkCode'],\n",
    "                'state': park['states'],\n",
    "                'addresses': park.get('addresses', []),\n",
    "                'description': park['description']\n",
    "            } for park in data['data']\n",
    "        ])\n",
    "        \n",
    "        # Move to the next page\n",
    "        start += limit\n",
    "        \n",
    "        # Break the loop if all parks have been retrieved\n",
    "        if int(start) >= int(data['total']):\n",
    "            break\n",
    "    \n",
    "    return parks"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_basic(endpoint, params):\n",
    "    \"\"\"\n",
    "    Use to get all data from endpoint without specific processing\n",
    "\n",
    "    endpoint: The API endpoint to call\n",
    "    params: The param dict to pass through the API call\n",
    "    \"\"\"\n",
    "    responses = []\n",
    "    limit = 50  # Number of results per page, maximum allowed by NPS API\n",
    "    start = 0   # Initial starting point for pagination\n",
    "    \n",
    "    while True:\n",
    "        params['limit'] = limit\n",
    "        params['start'] =  start\n",
    "        \n",
    "        request = requests.get(f\"{api_base_url}{endpoint}\", params=params)\n",
    "        request_data = request.json()\n",
    "\n",
    "        for record in request_data['data']:\n",
    "            responses.extend([record])\n",
    "        \n",
    "        # Move to the next page\n",
    "        start += limit\n",
    "        \n",
    "        # Break the loop if all responses have been retrieved\n",
    "        if int(start) >= int(request_data['total']):\n",
    "            break\n",
    "\n",
    "    return responses"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Create Synthetic Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "# list of parks\n",
    "parks_df = pd.DataFrame(get_parks({'api_key': api_key}))\n",
    "parks = parks_df['fullName'].tolist()\n",
    "park_codes = parks_df['parkCode'].tolist()\n",
    "park_lookup = dict(zip(parks, park_codes))\n",
    "collect_parks =  random.sample(parks, 50)#park_roots+parks"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Query API"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "park_info_df = pd.DataFrame()\n",
    "for park in collect_parks:\n",
    "        params = {'api_key': api_key,\n",
    "                'parkCode' : park_lookup[park]\n",
    "                        }\n",
    "        park_df = pd.DataFrame(get_parks(params)[0])\n",
    "        addresses_df = pd.json_normalize(park_df['addresses'])\n",
    "        temp_df = pd.concat([park_df.drop(columns=['addresses']), addresses_df], axis=1)\n",
    "        park_info_df = pd.concat([park_info_df, temp_df], ignore_index=True)  \n",
    "park_info_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>parkCode</th>\n",
       "      <th>activities</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>olym</td>\n",
       "      <td>[Astronomy, Biking, Boating, Camping, Climbing...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>pull</td>\n",
       "      <td>[Guided Tours, Museum Exhibits, Park Film, Sho...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>acad</td>\n",
       "      <td>[Arts and Culture, Astronomy, Biking, Boating,...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>yose</td>\n",
       "      <td>[Arts and Culture, Astronomy, Auto and ATV, Bi...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>zion</td>\n",
       "      <td>[Arts and Culture, Astronomy, Biking, Camping,...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "  parkCode                                         activities\n",
       "0     olym  [Astronomy, Biking, Boating, Camping, Climbing...\n",
       "1     pull  [Guided Tours, Museum Exhibits, Park Film, Sho...\n",
       "2     acad  [Arts and Culture, Astronomy, Biking, Boating,...\n",
       "3     yose  [Arts and Culture, Astronomy, Auto and ATV, Bi...\n",
       "4     zion  [Arts and Culture, Astronomy, Biking, Camping,..."
      ]
     },
     "execution_count": 52,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "park_activity_df = pd.DataFrame()\n",
    "for park in collect_parks:\n",
    "        parkcode = park_lookup[park]\n",
    "        params = {'api_key': api_key,\n",
    "                'parkCode': parkcode\n",
    "                        }\n",
    "        basic_data = get_basic('activities', params)\n",
    "        act_list = [[item['name'] for item in basic_data]]\n",
    "        temp_df = pd.DataFrame({'parkCode': parkcode, 'activities':act_list})\n",
    "        park_activity_df = pd.concat([park_activity_df, temp_df], ignore_index=True)  \n",
    "park_activity_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[{'id': '33A70DF9-543F-4AD8-B3D2-043E9130C98C', 'url': 'https://wsdot.wa.gov/about/news/2024/new-us-101-elwha-river-bridge-scheduled-open-following-nine-day-closure-us-101', 'title': 'July 12-22: HWY 101 Elwha Bridge Closed', 'parkCode': 'olym', 'description': 'Starting July 12, the Highway 101 Elwha Bridge will close for construction. Travelers should use State Routes 112 and 113 to access Lake Crescent and Barnes Point. Little River Rd will provide access to Madison Falls Trailhead and Olympic Hot Springs Rd.', 'category': 'Caution', 'relatedRoadEvents': [], 'lastIndexedDate': '2024-06-26 19:26:37.0'}, {'id': '4C7B9A25-ABC5-4FFF-9710-6B5560208427', 'url': 'https://www.nps.gov/olym/planyourvisit/fire-conditions-and-updates.htm', 'title': 'Trail Closures Due to Wildfire Damage', 'parkCode': 'olym', 'description': 'Elwha River Trail from the Hayden Pass junction to the Sixteen Mile camping area on the North Fork Quinault River Trail; Skyline Ridge Trail from the Lake Beauty Camp Trail junction to the Elwha River Trail near Low Divide', 'category': 'Caution', 'relatedRoadEvents': [], 'lastIndexedDate': '2024-04-23 12:25:17.0'}, {'id': '89715B7A-B3B9-4B71-BCEC-F17A2A02BC61', 'url': '', 'title': 'Expect Heavy Visitation in Hoh Rain Forest', 'parkCode': 'olym', 'description': 'Visitation to the Hoh Rain Forest is very popular during the summer months. Visitors should be prepared for 1-2 hour wait times at the entrance station between the hours of 10 AM and 5 PM. The parking lot fills early and then traffic is metered.', 'category': 'Information', 'relatedRoadEvents': [{'title': 'Upper Hoh Road Delays', 'id': '89715B7A-B3B9-4B71-BCEC-F17A2A02BC61', 'type': 'roadevent', 'url': 'https://www.nps.gov/olym/planyourvisit/conditions.htm'}], 'lastIndexedDate': '2023-07-26 16:24:43.0'}]\n",
      "[{'id': 'AF1925BE-C972-46FA-BF3F-FCE4A5427ECF', 'url': '', 'title': '111th Street Bridge to I-94 Closed for Construction', 'parkCode': 'pull', 'description': 'A full closure of the 111th St. bridge to I-94 is required for repairs. Motorists should follow the posted detour starting April 1.', 'category': 'Information', 'relatedRoadEvents': [], 'lastIndexedDate': '2024-04-01 17:34:26.0'}]\n",
      "[{'id': '53F32040-1871-4DEF-8738-59267B91DBCA', 'url': '', 'title': 'Avoid Water Contact at Sand Beach Lagoon (Not for Sand Beach)', 'parkCode': 'acad', 'description': 'Bacterial levels have exceeded public health standards at Sand Beach Lagoon and a Public Health Advisory has been posted. The public is advised against swimming at this beach until bacterial levels return to healthful levels. (Not for Sand Beach.)', 'category': 'Caution', 'relatedRoadEvents': [], 'lastIndexedDate': '2024-06-26 10:58:49.0'}, {'id': 'C112780A-B310-454C-BAA5-1C46C93F785C', 'url': '', 'title': 'Some Streets in Downtown Bar Harbor Closed for Construction Through Summer', 'parkCode': 'acad', 'description': 'To avoid traffic congestion, visitors should access Sand Beach via the Park Loop Road by following signs from the parkâ€™s Hulls Cove entrance on Route 3 (Eden Street) or Cadillac Mountain entrance on Route 233 (Eagle Lake Road) in Bar Harbor.', 'category': 'Information', 'relatedRoadEvents': [], 'lastIndexedDate': '2024-06-21 08:27:43.0'}, {'id': '1A36531A-5197-4110-86DF-069C45BBA327', 'url': '', 'title': 'Route 102A (Seawall Road) in Southwest Harbor is closed to through traffic', 'parkCode': 'acad', 'description': 'Due to storm damage, vehicles must access Seawall Campground, and Wonderland and Ship Harbor trails via the west end of Route 102A (Harbor Drive) in Bass Harbor. Route 102A (Seawall Road) is closed to through traffic at the seawall until further notice.', 'category': 'Information', 'relatedRoadEvents': [], 'lastIndexedDate': '2024-06-21 08:27:03.0'}, {'id': '1F00DE76-73CB-45AC-BD25-1EA4D99C7A81', 'url': '', 'title': 'Great Meadow Loop Trail closed along Great Meadow Drive', 'parkCode': 'acad', 'description': 'The trail crew will be removing old road asphalt with heavy equipment to restore the area to a more natural state. Hikers will be able to walk along the roadway of Great Meadow Drive to access trails into Sieur de Monts area.', 'category': 'Park Closure', 'relatedRoadEvents': [], 'lastIndexedDate': '2024-06-21 08:25:42.0'}, {'id': 'B79FC952-67F8-454D-A4F0-F787C06FF2C9', 'url': 'https://www.nps.gov/acad/planyourvisit/conditions.htm', 'title': 'Several trails closed for peregrine falcon nesting season (Precipice Trailhead parking lot closed)', 'parkCode': 'acad', 'description': 'Areas including Jordan Cliffs Trail, Precipice Trail, and Valley Cove Trail are closed to protect peregrine falcons from human disturbance during an annual nesting period. Precipice Trailhead parking lot has closed due to ongoing violations by hikers.', 'category': 'Park Closure', 'relatedRoadEvents': [], 'lastIndexedDate': '2024-06-14 09:12:01.0'}, {'id': '4E5CEB01-7851-4B0F-8C0B-34D26FF91133', 'url': '', 'title': 'Bubbles Divide Trail Closed for Repairs', 'parkCode': 'acad', 'description': 'A 0.3-mile section from the Jordan Pond Path to the Bubble Trail intersection is closed for repairs for several months.', 'category': 'Park Closure', 'relatedRoadEvents': [], 'lastIndexedDate': '2024-05-24 08:27:14.0'}, {'id': '5E3CA444-D027-4699-AE2D-47C0E915B889', 'url': 'https://www.nps.gov/acad/planyourvisit/conditions.htm', 'title': 'Storm Damage Significant', 'parkCode': 'acad', 'description': 'A winter storm on Wed Jan 10 led to significant damage to facilities throughout the park, such as the Ocean Path. Please be aware of debris, loose rocks, and uneven footing. Unless noted otherwise, all park areas remain open at this time.', 'category': 'Caution', 'relatedRoadEvents': [], 'lastIndexedDate': '2024-01-11 13:10:06.0'}]\n"
     ]
    },
    {
     "ename": "KeyError",
     "evalue": "'Yosemite National ParkHarpers Ferry National Historical Park'",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mKeyError\u001b[0m                                  Traceback (most recent call last)",
      "\u001b[1;32m~\\AppData\\Local\\Temp\\ipykernel_29140\\1086912152.py\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[0;32m      8\u001b[0m \u001b[0mpark_alert_df\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mpd\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mDataFrame\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      9\u001b[0m \u001b[1;32mfor\u001b[0m \u001b[0mpark\u001b[0m \u001b[1;32min\u001b[0m \u001b[0mcollect_parks\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 10\u001b[1;33m         \u001b[0mparkcode\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mpark_lookup\u001b[0m\u001b[1;33m[\u001b[0m\u001b[0mpark\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     11\u001b[0m         params = {'api_key': api_key,\n\u001b[0;32m     12\u001b[0m                 \u001b[1;34m'parkCode'\u001b[0m\u001b[1;33m:\u001b[0m \u001b[0mparkcode\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mKeyError\u001b[0m: 'Yosemite National ParkHarpers Ferry National Historical Park'"
     ]
    }
   ],
   "source": [
    "collect_parks = ['Olympic National Park',\n",
    "                'Pullman National Historical Park',\n",
    "                'Acadia National Park',\n",
    "                'Yosemite National Park'\n",
    "                'Harpers Ferry National Historical Park',\n",
    "                'Zion National Park']\n",
    "\n",
    "park_alert_df = pd.DataFrame()\n",
    "for park in collect_parks:\n",
    "        parkcode = park_lookup[park]\n",
    "        params = {'api_key': api_key,\n",
    "                'parkCode': parkcode\n",
    "                        }\n",
    "        basic_data = get_basic('alerts', params)\n",
    "        print(basic_data)\n",
    "        #act_list = [[item['name'] for item in basic_data]]\n",
    "        #temp_df = pd.DataFrame({'parkCode': parkcode, 'activities':act_list})\n",
    "        #park_alert_df = pd.concat([park_alert_df, temp_df], ignore_index=True)  \n",
    "#park_alert_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {},
   "outputs": [
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "\u001b[1;32m~\\AppData\\Local\\Temp\\ipykernel_24676\\2705672039.py\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[0;32m     40\u001b[0m     \u001b[1;34m\"Are there any special events at {entity}?\"\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;34m\"What events are planned at {entity}?\"\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;34m\"What events are currently happening at {entity}?\"\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;34m\"What activities and events are there at {entity}?\"\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     41\u001b[0m ]\n\u001b[1;32m---> 42\u001b[1;33m \u001b[0mParkEvents\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mget_info\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mapi_key\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mentities\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mparks_combined\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mentityCode\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;34m\"parkCode\"\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mendpoint\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;34m\"events\"\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mintent\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;34m\"ParkEvents\"\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mqueries\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mqueries\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mresponse_call\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;36m0\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     43\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     44\u001b[0m queries = [\n",
      "\u001b[1;32m~\\AppData\\Local\\Temp\\ipykernel_24676\\2323232239.py\u001b[0m in \u001b[0;36mget_info\u001b[1;34m(api_key, entities, entityCode, endpoint, intent, queries, response_call)\u001b[0m\n\u001b[0;32m     20\u001b[0m                 \u001b[1;31m# Park name needs to be converted to park code\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     21\u001b[0m                 params = {'api_key': api_key,\n\u001b[1;32m---> 22\u001b[1;33m                         \u001b[0mentityCode\u001b[0m\u001b[1;33m:\u001b[0m \u001b[0mpark_code_model\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mmap_park_code\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mquery\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mformat\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mentity\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mentity\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mpark_model\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mpark_vectorizer\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     23\u001b[0m                 }\n\u001b[0;32m     24\u001b[0m             \u001b[1;31m# if entityCode == \"stateCode\":\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mc:\\Users\\Courtney Gibson\\Documents\\02 - Education\\MADS 2021\\Capstone\\MADS_Capstone\\Data_API\\helper_functions\\park_code_model.py\u001b[0m in \u001b[0;36mmap_park_code\u001b[1;34m(user_input, model, vectorizer)\u001b[0m\n\u001b[0;32m    109\u001b[0m     \"\"\"\n\u001b[0;32m    110\u001b[0m     \u001b[1;31m# Transform the user input\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 111\u001b[1;33m     \u001b[0muser_input_vectorized\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mvectorizer\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mtransform\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m[\u001b[0m\u001b[0muser_input\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    112\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    113\u001b[0m     \u001b[1;31m# Predict the state code\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mc:\\python\\lib\\site-packages\\sklearn\\feature_extraction\\text.py\u001b[0m in \u001b[0;36mtransform\u001b[1;34m(self, raw_documents)\u001b[0m\n\u001b[0;32m   2100\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   2101\u001b[0m         \u001b[0mX\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0msuper\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mtransform\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mraw_documents\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m-> 2102\u001b[1;33m         \u001b[1;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_tfidf\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mtransform\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mX\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mcopy\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;32mFalse\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m   2103\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   2104\u001b[0m     \u001b[1;32mdef\u001b[0m \u001b[0m_more_tags\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mc:\\python\\lib\\site-packages\\sklearn\\feature_extraction\\text.py\u001b[0m in \u001b[0;36mtransform\u001b[1;34m(self, X, copy)\u001b[0m\n\u001b[0;32m   1672\u001b[0m             \u001b[1;31m# does not work as usual and we need to specify the attribute\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1673\u001b[0m             \u001b[1;31m# name:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m-> 1674\u001b[1;33m             \u001b[0mcheck_is_fitted\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mattributes\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;34m\"idf_\"\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mmsg\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;34m\"idf vector is not fitted\"\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m   1675\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1676\u001b[0m             \u001b[1;31m# *= doesn't work\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mc:\\python\\lib\\site-packages\\sklearn\\utils\\validation.py\u001b[0m in \u001b[0;36mcheck_is_fitted\u001b[1;34m(estimator, attributes, msg, all_or_any)\u001b[0m\n\u001b[0;32m   1211\u001b[0m         \u001b[1;32mif\u001b[0m \u001b[1;32mnot\u001b[0m \u001b[0misinstance\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mattributes\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m(\u001b[0m\u001b[0mlist\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mtuple\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1212\u001b[0m             \u001b[0mattributes\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;33m[\u001b[0m\u001b[0mattributes\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m-> 1213\u001b[1;33m         \u001b[0mfitted\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mall_or_any\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m[\u001b[0m\u001b[0mhasattr\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mestimator\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mattr\u001b[0m\u001b[1;33m)\u001b[0m \u001b[1;32mfor\u001b[0m \u001b[0mattr\u001b[0m \u001b[1;32min\u001b[0m \u001b[0mattributes\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m   1214\u001b[0m     \u001b[1;32melif\u001b[0m \u001b[0mhasattr\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mestimator\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;34m\"__sklearn_is_fitted__\"\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1215\u001b[0m         \u001b[0mfitted\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mestimator\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m__sklearn_is_fitted__\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mc:\\python\\lib\\site-packages\\sklearn\\utils\\validation.py\u001b[0m in \u001b[0;36m<listcomp>\u001b[1;34m(.0)\u001b[0m\n\u001b[0;32m   1211\u001b[0m         \u001b[1;32mif\u001b[0m \u001b[1;32mnot\u001b[0m \u001b[0misinstance\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mattributes\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m(\u001b[0m\u001b[0mlist\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mtuple\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1212\u001b[0m             \u001b[0mattributes\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;33m[\u001b[0m\u001b[0mattributes\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m-> 1213\u001b[1;33m         \u001b[0mfitted\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mall_or_any\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m[\u001b[0m\u001b[0mhasattr\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mestimator\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mattr\u001b[0m\u001b[1;33m)\u001b[0m \u001b[1;32mfor\u001b[0m \u001b[0mattr\u001b[0m \u001b[1;32min\u001b[0m \u001b[0mattributes\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m   1214\u001b[0m     \u001b[1;32melif\u001b[0m \u001b[0mhasattr\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mestimator\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;34m\"__sklearn_is_fitted__\"\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1215\u001b[0m         \u001b[0mfitted\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mestimator\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m__sklearn_is_fitted__\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mc:\\python\\lib\\site-packages\\sklearn\\feature_extraction\\text.py\u001b[0m in \u001b[0;36midf_\u001b[1;34m(self)\u001b[0m\n\u001b[0;32m   1692\u001b[0m         \u001b[1;31m# if _idf_diag is not set, this will raise an attribute error,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1693\u001b[0m         \u001b[1;31m# which means hasattr(self, \"idf_\") is False\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m-> 1694\u001b[1;33m         \u001b[1;32mreturn\u001b[0m \u001b[0mnp\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mravel\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_idf_diag\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0msum\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0maxis\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;36m0\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m   1695\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1696\u001b[0m     \u001b[1;33m@\u001b[0m\u001b[0midf_\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0msetter\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mc:\\python\\lib\\site-packages\\scipy\\sparse\\compressed.py\u001b[0m in \u001b[0;36msum\u001b[1;34m(self, axis, dtype, out)\u001b[0m\n\u001b[0;32m    611\u001b[0m         \u001b[1;31m# is in {None, -1, 0, 1}\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    612\u001b[0m         \u001b[1;32melse\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 613\u001b[1;33m             \u001b[1;32mreturn\u001b[0m \u001b[0mspmatrix\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0msum\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0maxis\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0maxis\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mdtype\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mdtype\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mout\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mout\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    614\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    615\u001b[0m     \u001b[0msum\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m__doc__\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mspmatrix\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0msum\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m__doc__\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mc:\\python\\lib\\site-packages\\scipy\\sparse\\base.py\u001b[0m in \u001b[0;36msum\u001b[1;34m(self, axis, dtype, out)\u001b[0m\n\u001b[0;32m   1027\u001b[0m             \u001b[1;31m# sum over columns\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1028\u001b[0m             ret = asmatrix(np.ones(\n\u001b[1;32m-> 1029\u001b[1;33m                 (1, m), dtype=res_dtype)) * self\n\u001b[0m\u001b[0;32m   1030\u001b[0m         \u001b[1;32melse\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1031\u001b[0m             \u001b[1;31m# sum over rows\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mc:\\python\\lib\\site-packages\\scipy\\sparse\\base.py\u001b[0m in \u001b[0;36m__rmul__\u001b[1;34m(self, other)\u001b[0m\n\u001b[0;32m    548\u001b[0m             \u001b[1;32mexcept\u001b[0m \u001b[0mAttributeError\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    549\u001b[0m                 \u001b[0mtr\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mnp\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0masarray\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mother\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mtranspose\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 550\u001b[1;33m             \u001b[1;32mreturn\u001b[0m \u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mtranspose\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m \u001b[1;33m*\u001b[0m \u001b[0mtr\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mtranspose\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    551\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    552\u001b[0m     \u001b[1;31m#######################\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mc:\\python\\lib\\site-packages\\scipy\\sparse\\base.py\u001b[0m in \u001b[0;36m__mul__\u001b[1;34m(self, other)\u001b[0m\n\u001b[0;32m    498\u001b[0m                 \u001b[1;32mraise\u001b[0m \u001b[0mValueError\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;34m'dimension mismatch'\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    499\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 500\u001b[1;33m             \u001b[0mresult\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_mul_vector\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mnp\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mravel\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mother\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    501\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    502\u001b[0m             \u001b[1;32mif\u001b[0m \u001b[0misinstance\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mother\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mnp\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mmatrix\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mc:\\python\\lib\\site-packages\\scipy\\sparse\\compressed.py\u001b[0m in \u001b[0;36m_mul_vector\u001b[1;34m(self, other)\u001b[0m\n\u001b[0;32m    472\u001b[0m         \u001b[1;31m# output array\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    473\u001b[0m         result = np.zeros(M, dtype=upcast_char(self.dtype.char,\n\u001b[1;32m--> 474\u001b[1;33m                                                other.dtype.char))\n\u001b[0m\u001b[0;32m    475\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    476\u001b[0m         \u001b[1;31m# csr_matvec or csc_matvec\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "queries = [\n",
    "    \"Tell me about {entity}\",\"What is the full name of {entity}?\",\"What is the address of {entity}?\",\"Which state is {entity} located in?\",\"Give me a description of {entity}\",\n",
    "    \"Where is {entity} located?\",\"Can you provide the full name of {entity}?\",\"What is the location of {entity}?\",\"Tell me the address of {entity}\",\n",
    "    \"In which state can I find {entity}?\",\"Describe {entity} to me\"\n",
    "]\n",
    "ParkInfo = get_info(api_key, entities = parks_combined, entityCode = \"parkCode\", endpoint = \"parks\", intent = \"ParkInfo\", queries = queries, response_call = 0)\n",
    "\n",
    "queries = [\n",
    "    \"Which parks are in {entity}?\",\"What parks can be found in {entity}?\",\"List the parks located in {entity}\",\"Are there any national parks in {entity}?\",\n",
    "    \"What national parks are in {entity}?\",\"Can you tell me the parks in {entity}?\",\"Give me a list of parks in {entity}\",\"Which national parks are located in {entity}?\",\n",
    "    \"What parks are available in {entity}?\",\"Tell me the parks that are in {entity}\"\n",
    "]\n",
    "#ParksInState = get_info(api_key, entities = dist_states, entityCode = \"stateCode\", endpoint = \"parks\", intent = \"ParksInState\", queries = queries, response_call = 0)\n",
    "\n",
    "queries = [\n",
    "    \"What activities can I do at {entity}?\",\"Tell me about the activities available at {entity}\",\"What can I do at {entity}?\",\"List the activities at {entity}\",\n",
    "    \"What recreational activities are offered at {entity}?\",\"What outdoor activities can I enjoy at {entity}?\",\"What kind of activities are there at {entity}?\",\n",
    "    \"What are the top activities at {entity}?\",\"What fun things can I do at {entity}?\",\"What activities are recommended at {entity}?\"\n",
    "]\n",
    "#raw_queries =  [\"What activities are there to do at \", \"Can I {activity} in \", \"Is {activity} available at \", \"What {activity} activities are available in \"]\n",
    "#queries = activity_queries(raw_queries, activities)\n",
    "ParkActivities = get_info(api_key, entities = parks_combined, entityCode = \"parkCode\", endpoint = \"activities\", intent = \"ParkActivities\", queries = queries, response_call = 0)\n",
    "\n",
    "queries = [\n",
    "    \"What alerts are active at {entity} currently?\",\"Are there any current alerts at {entity}?\",\"Tell me the active alerts at {entity}\",\"What are the current alerts for {entity}?\",\n",
    "    \"Which alerts are active in {entity} right now?\",\"List the active alerts at {entity}\",\"Are there any alerts at {entity}?\",\"What are the present alerts for {entity}?\",\n",
    "    \"Can you provide the active alerts for {entity}?\",\"What are the ongoing alerts at {entity}?\"\n",
    "]\n",
    "ParkAlerts = get_info(api_key, entities = parks_combined, entityCode = \"parkCode\", endpoint = \"alerts\", intent = \"ParkAlerts\", queries = queries, response_call = 0)\n",
    "\n",
    "queries = [\n",
    "    \"What amenities exist at {entity}?\",\"Tell me about the amenities at {entity}\",\"What facilities are available at {entity}?\",\"List the amenities at {entity}\",\n",
    "    \"What kind of amenities can I find at {entity}?\",\"What services and facilities does {entity} offer?\",\"What amenities should I expect at {entity}?\",\n",
    "    \"What conveniences are available at {entity}?\",\"What amenities does {entity} have?\",\"What facilities are provided at {entity}?\"\n",
    "]\n",
    "ParkAmenities = get_info(api_key, entities = parks_combined, entityCode = \"parkCode\", endpoint = \"amenities\", intent = \"ParkAmenities\", queries = queries, response_call = 0)\n",
    "\n",
    "queries = [\"What events are happening at {entity}?\",\"Tell me about the events at {entity}\",\"What upcoming events are scheduled at {entity}?\",\n",
    "    \"Are there any events at {entity}?\",\"What kind of events are held at {entity}?\",\"What events can I attend at {entity}?\",\n",
    "    \"Are there any special events at {entity}?\",\"What events are planned at {entity}?\",\"What events are currently happening at {entity}?\",\"What activities and events are there at {entity}?\"\n",
    "]\n",
    "ParkEvents = get_info(api_key, entities = parks_combined, entityCode = \"parkCode\", endpoint = \"events\", intent = \"ParkEvents\", queries = queries, response_call = 0)\n",
    "\n",
    "queries = [\n",
    "    \"How much does it cost to get into {entity}?\",\"What is the entry fee for {entity}?\", \"Tell me about the entrance fees for {entity}\",\n",
    "    \"What are the admission fees for {entity}?\",\"Are there any fees to visit {entity}?\",\"What is the cost of admission to {entity}?\",\n",
    "    \"How expensive is it to visit {entity}?\",\"What are the ticket prices for {entity}?\",\"Do I need to pay to enter {entity}?\",\"Are there any charges to access {entity}?\"\n",
    "]\n",
    "ParkFees = get_info(api_key, entities = parks_combined, entityCode = \"parkCode\", endpoint = \"feespasses\", intent = \"ParkFees\", queries = queries, response_call = 0)\n",
    "\n",
    "queries =  [\n",
    "    \"Where can I park at {entity}?\",\"Tell me about parking options at {entity}\",\"What are the parking facilities like at {entity}?\",\"Where should I park when visiting {entity}?\",\n",
    "    \"What parking areas are available at {entity}?\",\"Is there parking available at {entity}?\",\"How is parking managed at {entity}?\",\"Can I find parking near {entity}?\",\n",
    "    \"Are there designated parking lots at {entity}?\",\"What are the parking arrangements at {entity}?\"\n",
    "]\n",
    "#ParkParkingLots = get_info(api_key, entities = parks_combined, entityCode = \"parkCode\", endpoint = \"parkinglots\", intent = \"ParkParkingLots\", queries = queries, response_call = 0)\n",
    "\n",
    "queries = [\"What things can I do at {entity}?\",\"Tell me about attractions at {entity}\",\"What are the attractions at {entity}?\",\n",
    "    \"What are the main attractions of {entity}?\",\"What are the highlights of {entity}?\",\"What can I see and do at {entity}?\",\n",
    "    \"What are the recreational opportunities at {entity}?\",\"What are the popular things to do at {entity}?\",\n",
    "    \"What experiences are available at {entity}?\",\"What is there to do {entity}?\"]\n",
    "#ParkThingsToDo = get_info(api_key, entities = parks_combined, entityCode = \"parkCode\", endpoint = \"thingstodo\", intent = \"ParkThingsToDo\", queries = queries, response_call = 0)\n",
    "\n",
    "queries = [\"What tours can I take at {entity}?\",\"Tell me about guided tours at {entity}\",\"Are there any guided tours available at {entity}?\",\"What guided experiences are offered at {entity}?\",\n",
    "    \"Can I join any tours at {entity}?\",\"What kind of guided tours are available at {entity}?\",\"Are there ranger-led tours at {entity}?\",\n",
    "    \"What are the tour options at {entity}?\",\"How can I book a tour at {entity}?\",\"Are there any special tours or programs at {entity}?\"]\n",
    "#ParkTours = get_info(api_key, entities = parks_combined, entityCode = \"parkCode\", endpoint = \"tours\", intent = \"ParkTours\", queries = queries, response_call = 0)\n",
    "\n",
    "queries = [\"Where are the visitor centers located at {entity}?\",\"Tell me about visitor centers at {entity}\",\"What visitor centers can I find at {entity}?\",\n",
    "    \"Are there any visitor centers at {entity}?\",\"Where can I find information centers at {entity}?\",\"What are the visitor facilities like at {entity}?\",\"Can you guide me to the visitor centers at {entity}?\",\n",
    "    \"How many visitor centers are there at {entity}?\",\"What services do the visitor centers offer at {entity}?\",\"Are the visitor centers at {entity} open to the public?\"]\n",
    "#ParkVisitorCenters = get_info(api_key, entities = parks_combined, entityCode = \"parkCode\", endpoint = \"visitorcenters\", intent = \"ParkVisitorCenters\", queries = queries, response_call = 0)\n",
    "\n",
    "synthetic_queries_df = pd.concat([ParkInfo, ParkActivities, ParkAlerts, ParkAmenities, ParkEvents, ParkFees], axis=0, ignore_index=True)#ParkParkingLots, ParkThingsToDo, ParkTours, ParkVisitorCenters"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "metadata": {},
   "outputs": [],
   "source": [
    "synthetic_queries_df.to_csv('synthetic_queries.csv', index=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Prepare for GPT"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "metadata": {},
   "outputs": [],
   "source": [
    "synthetic_queries_df = pd.read_csv('synthetic_queries.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_df, val_df = train_test_split(synthetic_queries_df, test_size=0.2, random_state=42)\n",
    "train_df, temp_df = train_test_split(synthetic_queries_df, test_size=0.3, random_state=42)\n",
    "val_df, test_df = train_test_split(temp_df, test_size=0.5, random_state=42)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "213\n",
      "46\n"
     ]
    }
   ],
   "source": [
    "print(len(train_df))\n",
    "print(len(val_df))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "metadata": {},
   "outputs": [],
   "source": [
    "save_to_jsonl(train_df, 'fine_tune_train_data.jsonl')\n",
    "save_to_jsonl(val_df, 'fine_tune_val_data.jsonl')\n",
    "save_to_jsonl(test_df, 'fine_tune_test_data.jsonl')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Development"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_df, val_df = train_test_split(synthetic_queries_df, test_size=0.2, random_state=42)\n",
    "train_df, temp_df = train_test_split(synthetic_queries_df, test_size=0.3, random_state=42)\n",
    "val_df, test_df = train_test_split(temp_df, test_size=0.5, random_state=42)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "def create_prompt_response(row):\n",
    "    \"\"\"\n",
    "    Parses the synthetic data into GPT format\n",
    "    \"\"\"\n",
    "    dict = {'prompt': row['query'],\n",
    "            'completion':f\"endpoint: {row['api_call.endpoint']}, parkcode: {row['api_call.parkCode']}\"}\n",
    "    return dict"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def create_prompt_response(row):\n",
    "    \"\"\"\n",
    "    Parses the synthetic data into GPT format\n",
    "    \"\"\"\n",
    "    dict = {\"messages\": [\n",
    "        { \"role\": \"user\", \"content\": row['query'] },\n",
    "        {\n",
    "        \"role\": \"assistant\",\n",
    "        \"tool_calls\": [\n",
    "            {\n",
    "            \"id\": \"call_id\",\n",
    "            \"type\": \"function\",\n",
    "            \"function\": {\n",
    "                \"name\": \"call_endpoint\",\n",
    "                \"arguments\": {\"endpoint\": row['api_call.endpoint'],\"parkcode\":row['api_call.parkCode']}\n",
    "            }\n",
    "            }\n",
    "        ]\n",
    "        }\n",
    "    ],\n",
    "    \"parallel_tool_calls\": False,\n",
    "    \"tools\": [\n",
    "        {\n",
    "        \"type\": \"function\",\n",
    "        \"function\": {\n",
    "            \"name\": \"call_endpoint\",\n",
    "            \"description\": \"Make API call\",\n",
    "            \"parameters\": {\n",
    "            \"type\": \"object\",\n",
    "            \"properties\": {\n",
    "                \"endpoint\": {\n",
    "                    \"type\": \"string\",\n",
    "                    \"description\": \"The endpoint to call\"\n",
    "                },\n",
    "                \"parkcode\": { \"type\": \"string\", \"description\": \"The parkcode parameter to filter for\" }\n",
    "            },\n",
    "            \"required\": [\"endpoint\", \"parkcode\"]\n",
    "            } \n",
    "        }\n",
    "        }\n",
    "    ]\n",
    "    }\n",
    "    return dict"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 187,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[{'id': '09DF0950-D319-4557-A57E-04CD2F63FF42', 'name': 'Arts and Culture'},\n",
       " {'id': '13A57703-BB1A-41A2-94B8-53B692EB7238', 'name': 'Astronomy'},\n",
       " {'id': '7CE6E935-F839-4FEC-A63E-052B1DEF39D2', 'name': 'Biking'},\n",
       " {'id': '071BA73C-1D3C-46D4-A53C-00D5602F7F0E', 'name': 'Boating'},\n",
       " {'id': 'A59947B7-3376-49B4-AD02-C0423E08C5F7', 'name': 'Camping'},\n",
       " {'id': 'B12FAAB9-713F-4B38-83E4-A273F5A43C77', 'name': 'Climbing'},\n",
       " {'id': 'C11D3746-5063-4BD0-B245-7178D1AD866C', 'name': 'Compass and GPS'},\n",
       " {'id': 'AE42B46C-E4B7-4889-A122-08FE180371AE', 'name': 'Fishing'},\n",
       " {'id': '1DFACD97-1B9C-4F5A-80F2-05593604799E', 'name': 'Food'},\n",
       " {'id': 'B33DC9B6-0B7D-4322-BAD7-A13A34C584A3', 'name': 'Guided Tours'},\n",
       " {'id': '42FD78B9-2B90-4AA9-BC43-F10E9FEA8B5A', 'name': 'Hands-On'},\n",
       " {'id': 'BFF8C027-7C8F-480B-A5F8-CD8CE490BFBA', 'name': 'Hiking'},\n",
       " {'id': '0307955A-B65C-4CE4-A780-EB36BAAADF0B', 'name': 'Horse Trekking'},\n",
       " {'id': '5FF5B286-E9C3-430E-B612-3380D8138600', 'name': 'Ice Skating'},\n",
       " {'id': 'DF4A35E0-7983-4A3E-BC47-F37B872B0F25',\n",
       "  'name': 'Junior Ranger Program'},\n",
       " {'id': '4D224BCA-C127-408B-AC75-A51563C42411', 'name': 'Paddling'},\n",
       " {'id': '0C0D142F-06B5-4BE1-8B44-491B90F93DEB', 'name': 'Park Film'},\n",
       " {'id': '24380E3F-AD9D-4E38-BF13-C8EEB21893E7', 'name': 'Shopping'},\n",
       " {'id': 'F9B1D433-6B86-4804-AED7-B50A519A3B7C', 'name': 'Skiing'},\n",
       " {'id': 'C38B3C62-1BBF-4EA1-A1A2-35DE21B74C17', 'name': 'Snow Play'},\n",
       " {'id': '7C912B83-1B1B-4807-9B66-97C12211E48E', 'name': 'Snowmobiling'},\n",
       " {'id': '01D717BC-18BB-4FE4-95BA-6B13AD702038', 'name': 'Snowshoeing'},\n",
       " {'id': '587BB2D3-EC35-41B2-B3F7-A39E2B088AEE', 'name': 'Swimming'},\n",
       " {'id': '0B685688-3405-4E2A-ABBA-E3069492EC50', 'name': 'Wildlife Watching'}]"
      ]
     },
     "execution_count": 187,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# endpoint = 'activities'\n",
    "# park = 'acad'\n",
    "# params = {'api_key': api_key,\n",
    "#         'parkCode': park\n",
    "#                 }\n",
    "# test = get_basic(endpoint, params)\n",
    "# test"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}

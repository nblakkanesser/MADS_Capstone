{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Define Imports"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "import requests\n",
    "import pandas as pd \n",
    "import random\n",
    "from sklearn.feature_extraction.text import TfidfVectorizer\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.metrics import accuracy_score,f1_score,roc_auc_score\n",
    "\n",
    "from helper_functions import *\n",
    "from environment import env\n",
    "\n",
    "config = env.env()\n",
    "\n",
    "api_key = config['api_key']\n",
    "api_base_url = 'https://developer.nps.gov/api/v1/'\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Define Functions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_parks(params):\n",
    "    \"\"\"\n",
    "    Use to find a list of all park names, codes, states, addresses and descriptions from the NPS parks endpoint.\n",
    "    Can also be used to find specific park information.\n",
    "    \n",
    "    api_key: Personal API key to use in request\n",
    "    \"\"\"\n",
    "    parks = []\n",
    "    limit = 50  # Number of results per page, maximum allowed by NPS API\n",
    "    start = 0   # Initial starting point for pagination\n",
    "    \n",
    "    while True:\n",
    "        params = {\n",
    "            'api_key': api_key,\n",
    "            'limit': limit,\n",
    "            'start': start\n",
    "        }\n",
    "        \n",
    "        response = requests.get(f\"{api_base_url}parks\", params=params)\n",
    "        data = response.json()\n",
    "        \n",
    "        parks.extend([\n",
    "            {\n",
    "                'fullName': park['fullName'],\n",
    "                'parkCode': park['parkCode'],\n",
    "                'state': park['states'],\n",
    "                'addresses': park.get('addresses', []),\n",
    "                'description': park['description']\n",
    "            } for park in data['data']\n",
    "        ])\n",
    "        \n",
    "        # Move to the next page\n",
    "        start += limit\n",
    "        \n",
    "        # Break the loop if all parks have been retrieved\n",
    "        if int(start) >= int(data['total']):\n",
    "            break\n",
    "    \n",
    "    return parks"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "def generate_synthetic_states(raw_queries,park_codes,parks,park_abbreviations):\n",
    "    \"\"\"\n",
    "    Creates synthetic query data that will be used as training data for a model that identifies the state being asked about in a query.\n",
    "\n",
    "    raw_queries: List of queries to loop through and create data for.\n",
    "    park_codes: Park codes associated with the park name.\n",
    "    parks: List of parks to create the queries for.\n",
    "    park_abbreviations: List of park abbreviations to create the queries for.\n",
    "    \"\"\"\n",
    "    queries = []\n",
    "    query_park_name = []\n",
    "    query_park_code = []\n",
    "    for park_name, park_code, park_abbreviation in zip(parks, park_codes, park_abbreviations):\n",
    "        for query in raw_queries:\n",
    "            output = query.format(entity=park_name)\n",
    "            queries.append(output)\n",
    "            query_park_name.append(park_name)\n",
    "            query_park_code.append(park_code)\n",
    "\n",
    "            output = query.format(entity=park_abbreviation)\n",
    "            queries.append(output)\n",
    "            query_park_name.append(park_name)\n",
    "            query_park_code.append(park_code)\n",
    "        \n",
    "    data = {\n",
    "    'query': queries,\n",
    "    'parks': query_park_name,\n",
    "    'park_codes': query_park_code\n",
    "    }\n",
    "\n",
    "    return data\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "def train_model(synthetic_park_data):\n",
    "    # Vectorize the text data\n",
    "    vectorizer = TfidfVectorizer()\n",
    "    X = vectorizer.fit_transform(synthetic_park_data['query'])\n",
    "    y = synthetic_park_data['park_codes']\n",
    "\n",
    "    # Split the data\n",
    "    X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)\n",
    "\n",
    "    # Train a logistic regression model\n",
    "    model = LogisticRegression()\n",
    "    model.fit(X_train, y_train)\n",
    "\n",
    "    return model, vectorizer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "def trained_model():\n",
    "    synthetic_park_data = generate_synthetic_states(raw_queries,park_codes,parks,park_roots)\n",
    "    model, vectorizer = train_model(synthetic_park_data)\n",
    "    return model, vectorizer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "def map_park_code(user_input, model, vectorizer):\n",
    "    \"\"\"\n",
    "    Map user input to the correct state code using the trained model.\n",
    "\n",
    "    user_input: The query provided by the user.\n",
    "    model: Trained classification model.\n",
    "    vectorizer: Fitted vectorizer for text processing.\n",
    "    \"\"\"\n",
    "    # Transform the user input\n",
    "    user_input_vectorized = vectorizer.transform([user_input])\n",
    "    \n",
    "    # Predict the state code\n",
    "    predicted_park_code = model.predict(user_input_vectorized)[0]\n",
    "    \n",
    "    return predicted_park_code"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Define Variables"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "parks_df = pd.DataFrame(get_parks({'api_key': api_key}))\n",
    "parks = parks_df['fullName'].tolist()\n",
    "park_codes = parks_df['parkCode'].tolist()\n",
    "park_lookup = dict(zip(parks, park_codes))\n",
    "park_roots = nps_parks_root.nps_parks_root()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "raw_queries = ['What can I do in {entity}?',\n",
    "    'Where is {entity} located?',\n",
    "    'What are the best hiking trails in {entity}?',\n",
    "    'Are there camping facilities in {entity}?',\n",
    "    'How do I get to {entity}?',\n",
    "    'What wildlife can I see in {entity}?',\n",
    "    'Are there any guided tours available in {entity}?',\n",
    "    'What is the weather like in {entity}?',\n",
    "    'Can I bring my pet to {entity}?',\n",
    "    'Are there any entrance fees for {entity}?',\n",
    "    'What is the best time of year to visit {entity}?',\n",
    "    'Tell me about the history of {entity}.',\n",
    "    'Are there any special events happening at {entity}?',\n",
    "    'What are the must-see attractions in {entity}?',\n",
    "    'Can I swim in the lakes or rivers at {entity}?',\n",
    "    'What are the hours of operation for {entity}?',\n",
    "    'Is there lodging available inside {entity}?',\n",
    "    'What are the rules for fishing at {entity}?',\n",
    "    'Are there any restrictions on photography at {entity}?',\n",
    "    'Tell me about the geological features of {entity}.']\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model, vectorizer = trained_model()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "query = 'Where is {entity} located?'\n",
    "entity = 'Great Sand Dunes'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'grsa'"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "map_park_code(query.format(entity=entity), model, vectorizer)   "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
